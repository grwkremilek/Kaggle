{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# resources\n# https://medium.com/all-things-ai/in-depth-parameter-tuning-for-gradient-boosting-3363992e9bae","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt \nfrom matplotlib.legend_handler import HandlerLine2D\n\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import roc_curve, auc\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/titaniccleaningfeatureengineering/trainC.csv')\ntest = pd.read_csv('../input/titaniccleaningfeatureengineering/testC.csv')\nsubmission = pd.read_csv('../input/titanic/gender_submission.csv')\n\nX = train[train.columns[1:]]\ny = train['Survived']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# baseline with default parametes\ngbrt = GradientBoostingClassifier()\ngbrt.fit(X_train, y_train)\nprint(\"accuracy on training set: %f\" % gbrt.score(X_train, y_train))\nprint(\"accuracy on test set: %f\" % gbrt.score(X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission['Survived'] = gbrt.predict(test)\nsubmission.to_csv(\"submission.csv\", index = False)\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# learning_rate\n# shrinks the contribution of each tree\n\nlearning_rates = [1, 0.5, 0.25, 0.1, 0.05, 0.01]\ntrain_results = []\ntest_results = []\n\nfor eta in learning_rates:\n    gbrt = GradientBoostingClassifier(learning_rate=eta)\n    gbrt.fit(X_train, y_train)\n    train_pred = gbrt.predict(X_train)\n    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    train_results.append(roc_auc)\n    y_pred = gbrt.predict(X_test)\n    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    test_results.append(roc_auc)\n    \nline1, = plt.plot(learning_rates, train_results, label='Train AUC')\nline2, = plt.plot(learning_rates, test_results, label='Test AUC')\nplt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n\nplt.ylabel('AUC score')\nplt.xlabel('learning rate')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# N_estimators\n# represents the number of trees in the forest\n# the higher the number of trees the better to learn the data, but adding a lot of trees slows down the training proces\n\nn_estimators = [1, 2, 4, 8, 16, 32, 64]\ntrain_results = []\ntest_results = []\n\nfor estimator in n_estimators:\n    gbrt = GradientBoostingClassifier(n_estimators=estimator)\n    gbrt.fit(X_train, y_train)\n    train_pred = gbrt.predict(X_train)\n    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    train_results.append(roc_auc)\n    y_pred = gbrt.predict(X_test)\n    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    test_results.append(roc_auc)\n\nline1, = plt.plot(n_estimators, train_results, label='Train AUC')\nline2, = plt.plot(n_estimators, test_results, label='Test AUC')\nplt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n\nplt.ylabel('AUC score')\nplt.xlabel('n_estimators')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# max_depth\n# how deep the built tree can be (the deeper the tree, the more information it captures)\n\nmax_depths = np.linspace(1, 32, 32, endpoint=True)\ntrain_results = []\ntest_results = []\n\nfor max_depth in max_depths:\n    gbrt = GradientBoostingClassifier(max_depth=max_depth)\n    gbrt.fit(X_train, y_train)\n    train_pred = gbrt.predict(X_train)\n    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    train_results.append(roc_auc)\n    y_pred = gbrt.predict(X_test)\n    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    test_results.append(roc_auc)\n\nline1, = plt.plot(max_depths, train_results, label='Train AUC')\nline2, = plt.plot(max_depths, test_results, label='Test AUC')\nplt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n\nplt.ylabel('AUC score')\nplt.xlabel('n_estimators')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# min_samples_split\n# represents the minimum number of samples required to split an internal node\n# increase this parameter, the tree becomes more constrained as it has to consider more samples at each node\n\nmin_samples_splits = np.linspace(0.1, 1.0, 10, endpoint=True)\ntrain_results = []\ntest_results = []\n\nfor min_samples_split in min_samples_splits:\n    gbrt = GradientBoostingClassifier(min_samples_split=min_samples_split)\n    gbrt.fit(X_train, y_train)\n    train_pred = gbrt.predict(X_train)\n    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    train_results.append(roc_auc)\n    y_pred = gbrt.predict(X_test)\n    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    test_results.append(roc_auc)\n\nline1, = plt.plot(min_samples_splits, train_results, label='Train AUC')\nline2, = plt.plot(min_samples_splits, test_results, label='Test AUC')\nplt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n\nplt.ylabel('AUC score')\nplt.xlabel('min samples splits')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# min_samples_leaf\n# the minimum number of samples required to be at a leaf node\n\nmin_samples_leafs = np.linspace(0.1, 0.5, 5, endpoint=True)\ntrain_results = []\ntest_results = []\n\nfor min_samples_leaf in min_samples_leafs:\n    gbrt = GradientBoostingClassifier(min_samples_leaf=min_samples_leaf)\n    gbrt.fit(X_train, y_train)\n    train_pred = gbrt.predict(X_train)\n    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    train_results.append(roc_auc)\n    y_pred = gbrt.predict(X_test)\n    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    test_results.append(roc_auc)\n    \nline1, = plt.plot(min_samples_leafs, train_results, label='Train AUC')\nline2, = plt.plot(min_samples_leafs, test_results, label='Test AUC')\nplt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n\nplt.ylabel('AUC score')\nplt.xlabel('min samples leaf')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# max_features\n# represents the number of features to consider when looking for the best split\n\nmax_features = list(range(1,train.shape[1]))\ntrain_results = []\ntest_results = []\n\nfor max_feature in max_features:\n    gbrt = GradientBoostingClassifier(max_features=max_feature)\n    gbrt.fit(X_train, y_train)\n    train_pred = gbrt.predict(X_train)\n    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    train_results.append(roc_auc)\n    y_pred = gbrt.predict(X_test)\n    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    test_results.append(roc_auc)\n\nline1, = plt.plot(max_features, train_results, label='Train AUC')\nline2, = plt.plot(max_features, test_results, label='Test AUC')\nplt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n\nplt.ylabel('AUC score')\nplt.xlabel('max features')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# optimized parameters\n#gbrt_opt = GradientBoostingClassifier( min_samples_split=0.7)\n#gbrt_opt.fit(X_train, y_train)\n#print(\"accuracy on training set: %f\" % gbrt_opt.score(X_train, y_train))\n#print(\"accuracy on test set: %f\" % gbrt_opt.score(X_test, y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learning_rates = [1, 0.5, 0.25, 0.1, 0.05, 0.01]\nn_estimators = [1, 2, 4, 8, 16, 32, 64]\nmax_depths = np.linspace(1, 32, 32, endpoint=True)\nmin_samples_splits = np.linspace(0.1, 1.0, 10, endpoint=True)\nmin_samples_leafs = np.linspace(0.1, 0.5, 5, endpoint=True)\nmax_features = list(range(1,train.shape[1]))\n\nparam = { 'learning_rate' : learning_rates, \n         'n_estimators' : n_estimators, \n         'max_depth' : max_depths, \n         'min_samples_split' : min_samples_splits, \n         'min_samples_leaf' : min_samples_leafs,\n         'max_features' : max_features,\n        }\ncv = StratifiedShuffleSplit(n_splits=10, test_size=.30, random_state=15)\ngrid = GridSearchCV(GradientBoostingClassifier(), param, cv=cv, verbose = False, n_jobs=-1)\ngrid.fit(X,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (grid.best_score_)\nprint (grid.best_params_)\nprint(grid.best_estimator_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission['Survived'] = grid.predict(test)\nsubmission.to_csv(\"submission_GridSearchCV.csv\", index = False)\nsubmission.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"nbformat":4,"nbformat_minor":1}